I'm creating a simple website/blog to discuss the work that I'm doing. This blog will be technical and will have many images and videos.  

Summary of what I'm working on which will be included in the blog

I quit my job - principal data scientist at a large company - almost 3 months ago to pursue 1. making a game in Unreal Engine, 2. making a real-time generative AI framework for games and simulation, and to 3. work on a problem related to Hadwiger's conjecture.  

Background: I sold a startup that founded for ~12 million a few years ago and have about 3.2 million saved up - been average about 7% returns with a conservative to moderate investment portfolio. The startup was based on a set of algorithms/pipeline to work with geospatial data holistically (and losslessly) by creating a partition of the area of interest, with the blocks of the partition comprising contiguous areas of uniform information. Spatial operations become non-spatial by performing aggregations on these blocks. This was able to connect to non-spatial databases and even no-SQL databases. 

I recently finished a Master's degree at Harvard. I did well, finishing with a perfect GPA (all A's at Harvard, and A+'s at cross registered MIT courses). I had an amazing time there, but it was stressful and busy - especially while trying to work at the same time and raise a (then) infant son.  I have several patents and first author publications in mathematics and data science.  

For the game 1. I got the idea from one of my favorite books of all time, Yumi and the Nightmare Painter. The games takes place on a procedurally generated planetoid that is covered in a dark shroud from which monsters/nightmares spawn. Goal is to defeat monsters, build roads, lights that repel the shroud, defend/destroy against anti lights that attract the shroud, control tens of thousands of intelligent agents (see #2 below) and eventually defeat the source of the dark shroud on the opposite pole (from where you start) of the planet.  
This has been a lot of fun to work on an very highly technical. I had the spatial infrastructure set up using an inflated cube approach to generate the planet with an approximately equal area projection (a fifth order odd polynomial). I have real-time simulation system set up where I can run arbitrary simulations across the entire planetoid on the GPU with correct neighborhood sampling with correct wraparound sampling. I use this to perform thermal/hydraulic erosion, generate normals, generate rivers, material blending, tree, grass, object placement, water flow rendering, path finding etc. I'm now beginning to work on the real-time shroud which will be based on fluid mechanics (hopefully novel enough to attract attention and be fun to play). I've been working on this for about 2.5 months, including some time taken to learn unreal engine (which I was completely new to).  I've always dreamed about making and releasing a game. I started making (simple) games on a commodore 64 when I was ~6 years old and was hooked. 

I have an ability - action system with the following partial ordering. This could be symmetric or nearly symmetric around 0. High intelligent/complexity tasks -> +8 build towers, lead and guide other agents +7 build lights, build roads +6 collect resources +4 the player can *directly control this character* +3 explore +2 defend +1 attack 0 - slowly but randomly walk around The negative versions of this are in enemy control. More exposure to shroud decrease the highest ability for that agent. if it reaches 0, the poor soul randomly wanders around in confusion. If it drops below 0, the other side/enemy slowly gains control with abilities slowly increases with even more exposure to the shroud. Some strategy elements; Maybe the player will strategically allow exposure to the shroud for limited periods to enable attacks and exploration, with support from reserve agents to guide and lead.

For 2. I'm creating a real-time generative AI system to add intelligence to games. Similar to how lighting used to be baked into a world for global illumination, AI is baked into the world. The user defines a set of fundamental interface functions (task that can be accomplished), the shape and topology of the world, and all possible fundamental states. The first stage uses powerful LLMs to come up with a complete state space and composite strategies from this (the baking process). During actual game play, RL and very small LLMs are used in real time in compute shaders spread across frames to navigate this state graph and handle these composite strategies. This has also been a lot of fun to work though this is quite early. 